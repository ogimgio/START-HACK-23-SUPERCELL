{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook is for testing accuracy of our text model, as we may not fine-tune any model"
      ],
      "metadata": {
        "id": "jHa2iRNhxOPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GtqRbko_2NU",
        "outputId": "6511e680-7f0d-4627-eacd-bcd59e1a4453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz-30tAx8ZGQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#we get only messages_2 as we already have around 70k messages which is enough for testing our accuracy\n",
        "messages_2 = pd.read_csv(\"cleaned_messages_2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#lets split into offensive vs non offensive based wheter the risk is higher or lower 5\n",
        "bad = messages_2[messages_2['risk'] >= 5.0]['raw_message'].values\n",
        "good = messages_2[messages_2['risk'] <= 1.0]['raw_message'].iloc[0:10967].values\n",
        "data = np.concatenate((bad,good),axis=0)\n",
        "labels = np.concatenate((np.full(len(bad),1), np.full(len(bad),0)), axis=0)"
      ],
      "metadata": {
        "id": "v4FCxxdt9KDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffle labels and data the same way\n",
        "from sklearn.utils import shuffle\n",
        "data, labels = shuffle(data, labels)"
      ],
      "metadata": {
        "id": "MgcRWJTU86gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#Testing the accuracy\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"cardiffnlp/twitter-roberta-base-offensive\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# Set batch size and split the inputs into batches\n",
        "batch_size = 32\n",
        "num_batches = len(data) // batch_size + 1\n",
        "batches = [data[i*batch_size:(i+1)*batch_size] for i in range(num_batches)]\n",
        "\n",
        "# Generate predictions for each batch of inputs\n",
        "predicted_labels = []\n",
        "for batch in batches:\n",
        "    # Tokenize the batch\n",
        "    tokenized_inputs = tokenizer(batch.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate predictions for the batch\n",
        "    with torch.no_grad():\n",
        "        logits = model(tokenized_inputs['input_ids'], tokenized_inputs['attention_mask'])[0]\n",
        "        predicted_labels_batch = torch.argmax(logits, axis=1).tolist()\n",
        "    \n",
        "    predicted_labels += predicted_labels_batch\n",
        "\n",
        "# Print a classification report to evaluate model performance\n",
        "print(classification_report(labels, predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgF6fapV81bA",
        "outputId": "a56d9360-6f66-4cf2-8ea7-a143f4bedbb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.99      0.84     10967\n",
            "           1       0.98      0.62      0.76     10967\n",
            "\n",
            "    accuracy                           0.81     21934\n",
            "   macro avg       0.85      0.81      0.80     21934\n",
            "weighted avg       0.85      0.81      0.80     21934\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, we have a proper 81% accuracy, which is quite a good model. Because of this, we will proceed with inference on this model (in our app in Streamlit)"
      ],
      "metadata": {
        "id": "EyG6mjDIx7Qj"
      }
    }
  ]
}